{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blcqeptiItTF"
   },
   "source": [
    "\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "---\n",
    "\n",
    "In your upcoming project, you will download pre-computed bottleneck features.  In this notebook, we'll show you how to calculate VGG-16 bottleneck features on a toy dataset.  Note that unless you have a powerful GPU, computing the bottleneck features takes a significant amount of time.\n",
    "\n",
    "### 1. Load and Preprocess Sample Images\n",
    "\n",
    "Before supplying an image to a pre-trained network in Keras, there are some required preprocessing steps.  You will learn more about this in the project; for now, we have implemented this functionality for you in the first code cell of the notebook.  We have imported a very small dataset of 8 images and stored the  preprocessed image input as `img_input`.  Note that the dimensionality of this array is `(8, 224, 224, 3)`.  In this case, each of the 8 images is a 3D tensor, with shape `(224, 224, 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FLC6_JOVL2SE",
    "outputId": "33d2a1a8-c669-4d37-e2ea-7da10c2b06b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wM1IYts742Sn"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zXiHByjqBdr",
    "outputId": "82d61148-121b-47c9-9de7-8df96c25dcf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': None,\n",
       " 'data': [],\n",
       " 'filenames': array([], dtype=float64),\n",
       " 'target': array([], dtype=float64),\n",
       " 'target_names': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.datasets import load_files\n",
    "# path = '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/'\n",
    "# a_temp = load_files(path)\n",
    "# a_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUetILJt8Xmz",
    "outputId": "f9064cfb-527f-4688-a5a5-557cb19ef167"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Labrador_retriever_06449.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Curly-coated_retriever_03896.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Brittany_02625.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/American_water_spaniel_00648.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Labrador_retriever_06455.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/sopa.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Labrador_retriever_06457.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Welsh_springer_spaniel_08203.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img_paths = glob.glob(\"/content/drive/MyDrive/01 - My Documents/**\",recursive=True)\n",
    "# img_paths\n",
    "img_paths = glob.glob(\"/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/*.jpg\")\n",
    "img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTKIOdNNDFal",
    "outputId": "83ee550b-1f52-43fa-8de4-b0723e3aa468"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Labrador_retriever_06449.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Curly-coated_retriever_03896.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Brittany_02625.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/American_water_spaniel_00648.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Labrador_retriever_06455.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/sopa.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Labrador_retriever_06457.jpg',\n",
       " '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Welsh_springer_spaniel_08203.jpg']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvdoLGKCjjKX"
   },
   "outputs": [],
   "source": [
    "# path = '/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/Labrador_retriever_06449.jpg'\n",
    "\n",
    "# def a_fun_to_read_image_in_array(img_path):\n",
    "#   return np.expand_dims( image.img_to_array( image.load_img(path, target_size=(224,224))) , axis = 0 )\n",
    "\n",
    "# a_fun_to_read_image_in_array(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zoa8mA4tItTO",
    "outputId": "5012c371-4534-4ee0-db7f-c1ee1919800f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "\n",
    "# a_array = paths_to_tensor(img_paths)\n",
    "\n",
    "\n",
    "# calculate the image input. you will learn more about how this works the project!\n",
    "img_input = preprocess_input(paths_to_tensor(img_paths))\n",
    "\n",
    "print(img_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMC_KQvQItTS"
   },
   "source": [
    "### 2. Recap How to Import VGG-16\n",
    "\n",
    "Recall how we import the VGG-16 network (including the final classification layer) that has been pre-trained on ImageNet.\n",
    "\n",
    "![VGG-16 model](figures/vgg16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ffxy0HumItTU",
    "outputId": "e6ebfe11-77a3-49c4-e769-79d6bef0e5ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 3s 0us/step\n",
      "553476096/553467096 [==============================] - 3s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oV9iKdOaItTV"
   },
   "source": [
    "For this network, `model.predict` returns a 1000-dimensional probability vector containing the predicted probability that an image returns each of the 1000 ImageNet categories.  The dimensionality of the obtained output from passing `img_input` through the model is `(8, 1000)`.  The first value of `8` merely denotes that 8 images were passed through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGqOY-DeItTX"
   },
   "outputs": [],
   "source": [
    "x = model.predict(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDxSbQM2f3lJ",
    "outputId": "94d13913-0270-4b94-8b0a-bf512b7403a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iu0rQxdIItTY"
   },
   "source": [
    "### 3. Import the VGG-16 Model, with the Final Fully-Connected Layers Removed\n",
    "\n",
    "When performing transfer learning, we need to remove the final layers of the network, as they are too specific to the ImageNet database.  This is accomplished in the code cell below.\n",
    "\n",
    "![VGG-16 model for transfer learning](figures/vgg16_transfer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iB6UTny-ItTa",
    "outputId": "6c3f3df7-f7e2-4377-f56c-42a012c85e01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 0s 0us/step\n",
      "58900480/58889256 [==============================] - 0s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16(include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Vsx61jMItTb"
   },
   "source": [
    "### 4. Extract Output of Final Max Pooling Layer\n",
    "\n",
    "Now, the network stored in `model` is a truncated version of the VGG-16 network, where the final three fully-connected layers have been removed.  In this case, `model.predict` returns a 3D array (with dimensions $7\\times 7\\times 512$) corresponding to the final max pooling layer of VGG-16.  The dimensionality of the obtained output from passing `img_input` through the model is `(8, 7, 7, 512)`.  The first value of `8` merely denotes that 8 images were passed through the network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CalZsgc7lD4"
   },
   "outputs": [],
   "source": [
    "bottle_neck_features = model.predict(img_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3x_xknEJKpC",
    "outputId": "194dc504-a09e-4545-e213-15c42cee21d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 7, 7, 512)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottle_neck_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NS3ME9UDItTd"
   },
   "outputs": [],
   "source": [
    "np.savez('botleneck_features_testing.npz', model.predict(img_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4Fq1jNRLzIk"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files   \n",
    "from keras.utils import np_utils    \n",
    "\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    # dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    # return dog_files, dog_targets\n",
    "    return dog_targets\n",
    "\n",
    "# train_targets = load_dataset('/content/drive/MyDrive/dogImages/train')\n",
    "train_targets = load_dataset('/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/')\n",
    "\n",
    "\n",
    "# valid_targets = load_dataset('/content/drive/MyDrive/dogImages/valid')\n",
    "# test_targets = load_dataset('/content/drive/MyDrive/dogImages/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jgUFnA9iXBWK",
    "outputId": "2d88c239-819f-48f4-982d-5f2fa8efde8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 133), dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kv7yVvaXZsWX",
    "outputId": "870c1b29-96de-4ca5-df36-0cc8cc5ca3a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['133.Yorkshire_terrier',\n",
       " '044.Cane_corso',\n",
       " '090.Italian_greyhound',\n",
       " '116.Parson_russell_terrier',\n",
       " '012.Australian_shepherd',\n",
       " '021.Belgian_sheepdog',\n",
       " '100.Lowchen',\n",
       " '063.English_springer_spaniel',\n",
       " '092.Keeshond',\n",
       " '052.Clumber_spaniel',\n",
       " '095.Kuvasz',\n",
       " '056.Dachshund',\n",
       " '048.Chihuahua',\n",
       " '038.Brussels_griffon',\n",
       " '120.Pharaoh_hound',\n",
       " '066.Field_spaniel',\n",
       " '114.Otterhound',\n",
       " '080.Greater_swiss_mountain_dog',\n",
       " '050.Chinese_shar-pei',\n",
       " '097.Lakeland_terrier',\n",
       " '006.American_eskimo_dog',\n",
       " '016.Beagle',\n",
       " '108.Norwegian_buhund',\n",
       " '005.Alaskan_malamute',\n",
       " '130.Welsh_springer_spaniel',\n",
       " '128.Smooth_fox_terrier',\n",
       " '073.German_wirehaired_pointer',\n",
       " '055.Curly-coated_retriever',\n",
       " '015.Basset_hound',\n",
       " '106.Newfoundland',\n",
       " '047.Chesapeake_bay_retriever',\n",
       " '009.American_water_spaniel',\n",
       " '004.Akita',\n",
       " '022.Belgian_tervuren',\n",
       " '079.Great_pyrenees',\n",
       " '030.Border_terrier',\n",
       " '014.Basenji',\n",
       " '072.German_shorthaired_pointer',\n",
       " '033.Bouvier_des_flandres',\n",
       " '025.Black_and_tan_coonhound',\n",
       " '031.Borzoi',\n",
       " '117.Pekingese',\n",
       " '020.Belgian_malinois',\n",
       " '051.Chow_chow',\n",
       " '096.Labrador_retriever',\n",
       " '064.English_toy_spaniel',\n",
       " '103.Mastiff',\n",
       " '102.Manchester_terrier',\n",
       " '113.Old_english_sheepdog',\n",
       " '039.Bull_terrier',\n",
       " '105.Neapolitan_mastiff',\n",
       " '057.Dalmatian',\n",
       " '115.Papillon',\n",
       " '060.Dogue_de_bordeaux',\n",
       " '098.Leonberger',\n",
       " '110.Norwegian_lundehund',\n",
       " '085.Irish_red_and_white_setter',\n",
       " '046.Cavalier_king_charles_spaniel',\n",
       " '131.Wirehaired_pointing_griffon',\n",
       " '059.Doberman_pinscher',\n",
       " '129.Tibetan_mastiff',\n",
       " '081.Greyhound',\n",
       " '040.Bulldog',\n",
       " '121.Plott',\n",
       " '126.Saint_bernard',\n",
       " '032.Boston_terrier',\n",
       " '053.Cocker_spaniel',\n",
       " '111.Norwich_terrier',\n",
       " '062.English_setter',\n",
       " '041.Bullmastiff',\n",
       " '068.Flat-coated_retriever',\n",
       " '099.Lhasa_apso',\n",
       " '094.Komondor',\n",
       " '093.Kerry_blue_terrier',\n",
       " '045.Cardigan_welsh_corgi',\n",
       " '018.Beauceron',\n",
       " '071.German_shepherd_dog',\n",
       " '013.Australian_terrier',\n",
       " '029.Border_collie',\n",
       " '011.Australian_cattle_dog',\n",
       " '107.Norfolk_terrier',\n",
       " '001.Affenpinscher',\n",
       " '091.Japanese_chin',\n",
       " '118.Pembroke_welsh_corgi',\n",
       " '017.Bearded_collie',\n",
       " '037.Brittany',\n",
       " '023.Bernese_mountain_dog',\n",
       " '010.Anatolian_shepherd_dog',\n",
       " '083.Ibizan_hound',\n",
       " '127.Silky_terrier',\n",
       " '088.Irish_water_spaniel',\n",
       " '028.Bluetick_coonhound',\n",
       " '003.Airedale_terrier',\n",
       " '042.Cairn_terrier',\n",
       " '119.Petit_basset_griffon_vendeen',\n",
       " '019.Bedlington_terrier',\n",
       " '101.Maltese',\n",
       " '104.Miniature_schnauzer',\n",
       " '067.Finnish_spitz',\n",
       " '065.Entlebucher_mountain_dog',\n",
       " '034.Boxer',\n",
       " '132.Xoloitzcuintli',\n",
       " '087.Irish_terrier',\n",
       " '074.Giant_schnauzer',\n",
       " '026.Black_russian_terrier',\n",
       " '082.Havanese',\n",
       " '123.Pomeranian',\n",
       " '027.Bloodhound',\n",
       " '049.Chinese_crested',\n",
       " '002.Afghan_hound',\n",
       " '035.Boykin_spaniel',\n",
       " '058.Dandie_dinmont_terrier',\n",
       " '008.American_staffordshire_terrier',\n",
       " '076.Golden_retriever',\n",
       " '007.American_foxhound',\n",
       " '084.Icelandic_sheepdog',\n",
       " '109.Norwegian_elkhound',\n",
       " '070.German_pinscher',\n",
       " '125.Portuguese_water_dog',\n",
       " '077.Gordon_setter',\n",
       " '089.Irish_wolfhound',\n",
       " '061.English_cocker_spaniel',\n",
       " '078.Great_dane',\n",
       " '024.Bichon_frise',\n",
       " '112.Nova_scotia_duck_tolling_retriever',\n",
       " '043.Canaan_dog',\n",
       " '036.Briard',\n",
       " '075.Glen_of_imaal_terrier',\n",
       " '086.Irish_setter',\n",
       " '054.Collie',\n",
       " '122.Pointer',\n",
       " '124.Poodle',\n",
       " '069.French_bulldog']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "QoJwLw67ZzoZ",
    "outputId": "fefcd33e-f368-460d-c1cb-4f84ada1ebac"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e6d644211b43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \"\"\"\n\u001b[0;32m---> 62\u001b[0;31m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '133.Yorkshire_terrier'"
     ]
    }
   ],
   "source": [
    "np_utils.to_categorical(np.array(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "MC7xT_RsZibl",
    "outputId": "7c190e54-4d56-4354-aa16-8a43315d3879"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-3a6eb4c1f55f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/content/drive/MyDrive/dogImages/train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m133\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# for i in p:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret '133' as a data type"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.utils import np_utils    \n",
    "p=os.listdir(r'/content/drive/MyDrive/dogImages/train')\n",
    "\n",
    "# np_utils.to_categorical(np.array(p, 133))\n",
    "\n",
    "# for i in p:\n",
    "#     if os.path.isdir(i):\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gK4dn_rEXNy2",
    "outputId": "1949e81e-91fa-48ea-c750-cb0fd623bdef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_files('/content/drive/MyDrive/AML_TL_SAMPLE_IMAGES/images/')\n",
    "np_utils.to_categorical(np.array(data['target']), 133)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p60yLPOfItTe"
   },
   "source": [
    "This is exactly how we calculate the bottleneck features for your project!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
